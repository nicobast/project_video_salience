<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Nico Bast" />


<title>salience_extraction</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<link rel="icon" href="https://github.com/workflowr/workflowr-assets/raw/master/img/reproducible.png">
<!-- Add a small amount of space between sections. -->
<style type="text/css">
div.section {
  padding-top: 12px;
}
</style>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">project_video_salience</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="about.html">About</a>
</li>
<li>
  <a href="license.html">License</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/nicobast/project_video_salience">
    <span class="fa fa-github"></span>
     
    Source code
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">salience_extraction</h1>
<h4 class="author">Nico Bast</h4>
<h4 class="date">17 3 2021</h4>

</div>


<p>
<button type="button" class="btn btn-default btn-workflowr btn-workflowr-report" data-toggle="collapse" data-target="#workflowr-report">
<span class="glyphicon glyphicon-list" aria-hidden="true"></span> workflowr <span class="glyphicon glyphicon-exclamation-sign text-danger" aria-hidden="true"></span>
</button>
</p>
<div id="workflowr-report" class="collapse">
<ul class="nav nav-tabs">
<li class="active">
<a data-toggle="tab" href="#summary">Summary</a>
</li>
<li>
<a data-toggle="tab" href="#checks"> Checks <span class="glyphicon glyphicon-exclamation-sign text-danger" aria-hidden="true"></span> </a>
</li>
<li>
<a data-toggle="tab" href="#versions">Past versions</a>
</li>
</ul>
<div class="tab-content">
<div id="summary" class="tab-pane fade in active">
<p>
<strong>Last updated:</strong> 2021-09-13
</p>
<p>
<strong>Checks:</strong> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> 6 <span class="glyphicon glyphicon-exclamation-sign text-danger" aria-hidden="true"></span> 1
</p>
<p>
<strong>Knit directory:</strong> <code>project_video_salience/</code> <span class="glyphicon glyphicon-question-sign" aria-hidden="true" title="This is the local directory in which the code in this file was executed."> </span>
</p>
<p>
This reproducible <a href="http://rmarkdown.rstudio.com">R Markdown</a> analysis was created with <a
  href="https://github.com/jdblischak/workflowr">workflowr</a> (version 1.6.2). The <em>Checks</em> tab describes the reproducibility checks that were applied when the results were created. The <em>Past versions</em> tab lists the development history.
</p>
<hr>
</div>
<div id="checks" class="tab-pane fade">
<div class="panel-group" id="workflowr-checks">
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRMarkdownfilestronguptodate"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>R Markdown file:</strong> up-to-date </a>
</p>
</div>
<div id="strongRMarkdownfilestronguptodate" class="panel-collapse collapse">
<div class="panel-body">
<p>Great! Since the R Markdown file has been committed to the Git repository, you know the exact version of the code that produced these results.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongEnvironmentstrongempty"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Environment:</strong> empty </a>
</p>
</div>
<div id="strongEnvironmentstrongempty" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! The global environment was empty. Objects defined in the global environment can affect the analysis in your R Markdown file in unknown ways. For reproduciblity it’s best to always run the code in an empty environment.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongSeedstrongcodesetseed20210113code"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Seed:</strong> <code>set.seed(20210113)</code> </a>
</p>
</div>
<div id="strongSeedstrongcodesetseed20210113code" class="panel-collapse collapse">
<div class="panel-body">
<p>The command <code>set.seed(20210113)</code> was run prior to running the code in the R Markdown file. Setting a seed ensures that any results that rely on randomness, e.g. subsampling or permutations, are reproducible.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongSessioninformationstrongrecorded"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Session information:</strong> recorded </a>
</p>
</div>
<div id="strongSessioninformationstrongrecorded" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! Recording the operating system, R version, and package versions is critical for reproducibility.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongCachestrongnone"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Cache:</strong> none </a>
</p>
</div>
<div id="strongCachestrongnone" class="panel-collapse collapse">
<div class="panel-body">
<p>Nice! There were no cached chunks for this analysis, so you can be confident that you successfully produced the results during this run.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongFilepathsstrongabsolute"> <span class="glyphicon glyphicon-exclamation-sign text-danger" aria-hidden="true"></span> <strong>File paths:</strong> absolute </a>
</p>
</div>
<div id="strongFilepathsstrongabsolute" class="panel-collapse collapse">
<div class="panel-body">
<p>
Using absolute paths to the files within your workflowr project makes it difficult for you and others to run your code on a different machine. Change the absolute path(s) below to the suggested relative path(s) to make your code more reproducible.
</p>
<table class="table table-condensed table-hover">
<thead>
<tr>
<th style="text-align:left;">
absolute
</th>
<th style="text-align:left;">
relative
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
C:_video_salience_video_to_images.py
</td>
<td style="text-align:left;">
split_video_to_images.py
</td>
</tr>
<tr>
<td style="text-align:left;">
C:_video_salience_salience_in_video.py
</td>
<td style="text-align:left;">
static_salience_in_video.py
</td>
</tr>
<tr>
<td style="text-align:left;">
C:_video_salience_salience_in_video_MOG2.py
</td>
<td style="text-align:left;">
motion_salience_in_video_MOG2.py
</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRepositoryversionstrongahrefhttpsgithubcomnicobastprojectvideosaliencetree448552710510b48760e9f28e6fb6dcd454ac3caetargetblank4485527a"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Repository version:</strong> <a href="https://github.com/nicobast/project_video_salience/tree/448552710510b48760e9f28e6fb6dcd454ac3cae" target="_blank">4485527</a> </a>
</p>
</div>
<div id="strongRepositoryversionstrongahrefhttpsgithubcomnicobastprojectvideosaliencetree448552710510b48760e9f28e6fb6dcd454ac3caetargetblank4485527a" class="panel-collapse collapse">
<div class="panel-body">
<p>
Great! You are using Git for version control. Tracking code development and connecting the code version to the results is critical for reproducibility.
</p>
<p>
The results in this page were generated with repository version <a href="https://github.com/nicobast/project_video_salience/tree/448552710510b48760e9f28e6fb6dcd454ac3cae" target="_blank">4485527</a>. See the <em>Past versions</em> tab to see a history of the changes made to the R Markdown and HTML files.
</p>
<p>
Note that you need to be careful to ensure that all relevant files for the analysis have been committed to Git prior to generating the results (you can use <code>wflow_publish</code> or <code>wflow_git_commit</code>). workflowr only checks the R Markdown file, but you know if there are other scripts or data files that it depends on. Below is the status of the Git repository when the results were generated:
</p>
<pre><code>
Ignored files:
    Ignored:    .Rhistory
    Ignored:    .Rproj.user/
    Ignored:    analysis/data_analysis_salience_cache/

Untracked files:
    Untracked:  .PowerFolder/
    Untracked:  analysis/Results in unmatched sample.docx
    Untracked:  code/OLD/
    Untracked:  code/analysis_salience_130121.R
    Untracked:  code/analysis_salience_150421.R
    Untracked:  code/mean_salience_per_video.R
    Untracked:  code/preprocessing1_matching_gaze_and_salience_data.R
    Untracked:  code/preprocessing2_matching_gaze_and_motionsalience_data.R
    Untracked:  code/preprocessing3_datareduction_adding_additional_data.R
    Untracked:  code/python_code_salience_extraction/
    Untracked:  code/sesnory_subgroup_analysis.R
    Untracked:  data/merged_data/
    Untracked:  data/video_stimuli_scenes.csv
    Untracked:  desktop.ini
    Untracked:  manuscript/
    Untracked:  output/gaze_animate_sample.mp4
    Untracked:  output/gaze_animate_sample_dollhouse_scene5.mp4
    Untracked:  output/motion_salience/
    Untracked:  output/motion_salience_video_pingudoctors_scene0.avi
    Untracked:  output/salience_video_artist.avi
    Untracked:  output/stimuli_pics/
    Untracked:  output/stimuli_salience/
    Untracked:  output/stimuli_scene/
    Untracked:  project_init_workflow.R

Unstaged changes:
    Modified:   code/README.md
    Modified:   data/README.md

</code></pre>
<p>
Note that any generated files, e.g. HTML, png, CSS, etc., are not included in this status report because it is ok for generated content to have uncommitted changes.
</p>
</div>
</div>
</div>
</div>
<hr>
</div>
<div id="versions" class="tab-pane fade">

<p>
These are the previous versions of the repository in which changes were made to the R Markdown (<code>analysis/extract_salience.Rmd</code>) and HTML (<code>docs/extract_salience.html</code>) files. If you’ve configured a remote Git repository (see <code>?wflow_git_remote</code>), click on the hyperlinks in the table below to view the files as they were in that past version.
</p>
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
File
</th>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
<th>
Message
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/nicobast/project_video_salience/blob/448552710510b48760e9f28e6fb6dcd454ac3cae/analysis/extract_salience.Rmd" target="_blank">4485527</a>
</td>
<td>
nicobast
</td>
<td>
2021-09-13
</td>
<td>
Publish the initial files for myproject
</td>
</tr>
</tbody>
</table>
</div>
<hr>
</div>
</div>
</div>
<p>use of <a href="https://opencv.org/releases/">OpenCV</a> in <a href="https://www.python.org/downloads/release/python-380/">Python 3.8</a>. Open CV includes a salience API that is further described <a href="https://www.pyimagesearch.com/2018/07/16/opencv-saliency-detection/">here</a>.</p>
<p>We apply the following salience algorithms:</p>
<ul>
<li>perceptual salience –&gt; <a href="https://ieeexplore.ieee.org/abstract/document/4270292">spectral residual approach</a> –&gt; cv2.saliency.StaticSaliencySpectralResidual_create()</li>
<li>motion salience –&gt; <a href="https://ieeexplore.ieee.org/abstract/document/1333992">Gaussian mixture model</a> –&gt; cv2.createBackgroundSubtractorMOG2()</li>
</ul>
<div id="install-opencv-in-python-3.8" class="section level1">
<h1>install OpenCV in Python 3.8</h1>
<p>execute in CMD</p>
<pre class="cmd"><code>

### 1 INSTALL: openCV to python
### contrib also contains additional modules of openCV including the salience API

pip install opencv-contrib-python

### 2 SETUP:

py # change to python and check version
import.cv2
cv2.__version__
cv.saliency #check whether saliency module of opencv is installed

#vid_path = &quot;C:/Users/Nico/PowerFolders/Paper_AIMS-LEAP_ETcore/stimuli/nonhuman/&quot; # define folder with videos in a directory in split_video_to_images.py
</code></pre>
</div>
<div id="perceptual-salience---opencv" class="section level1">
<h1>perceptual salience - OpenCV</h1>
<p>execute as BAT file</p>
<pre class="r"><code>@echo off

ECHO Identify STATIC SALIENCE in VIDEO files:
ECHO INFO: splits video into images that are separately analyzed
ECHO -----------------------------------------------------

REM set /p path=&quot;Enter Path with Video files: &quot;
set path=&quot;C:\Users\Nico\PowerFolders\data_LEAP\stimuli\nonhuman&quot;
set /p name=&quot;Enter Name of the Video: &quot;

REM e.g. path = &quot;C:/Users/Nico/PowerFolders/Paper_AIMS-LEAP_ETcore/stimuli/nonhuman&quot;
REM e.g. path = &quot;birds&quot;

REM independent of environment variables (full path files)

ECHO SPLITTING VIDEO...
&quot;C:\Python38\python.exe&quot; &quot;C:\Users\Nico\PowerFolders\project_video_salience\split_video_to_images.py&quot; %name% %path%
ECHO ...DONE

ECHO IDENTIFY SALIENCE...
&quot;C:\Python38\python.exe&quot; &quot;C:\Users\Nico\PowerFolders\project_video_salience\static_salience_in_video.py&quot; %name%
ECHO ...DONE

REM with environment variables
REM start &quot;split_video&quot; python split_video_to_images.py
REM start &quot;salience_detection&quot; python static_salience_in_video.py %name%

PAUSE</code></pre>
<div id="split-video-to-images" class="section level2">
<h2>split video to images</h2>
<pre class="python"><code>
import cv2
import sys
import os

vid_name = sys.argv[1]
vid_path = sys.argv[2]
#vid_name = &quot;coralreef&quot;
#vid_path = &quot;C:/Users/Nico/PowerFolders/Paper_AIMS-LEAP_ETcore/stimuli/nonhuman&quot;

#get the path of the vid_name in vid_path (search for the video)
for path in os.listdir(vid_path):
    if vid_name in path:
        full_path = os.path.join(vid_path, path)


output_folder = &quot;stimuli_pics&quot;
if not os.path.exists(output_folder):
    os.mkdir(output_folder)
os.chdir(output_folder)

#create folder for pics if not existing
if not os.path.exists(vid_name):
    os.mkdir(vid_name)
os.chdir(vid_name)

#loop to create pics from vid
cap = cv2.VideoCapture(full_path)
i=0
while(cap.isOpened()):
    ret, frame = cap.read()
    if ret == False:
        break
    cv2.imwrite(vid_name+str(i)+&#39;.jpg&#39;,frame)
    print(vid_name+str(i)+&#39;.jpg&#39;)
    i+=1

cap.release()
cv2.destroyAllWindows()
</code></pre>
</div>
<div id="perceptual-salience-extraction" class="section level2">
<h2>perceptual salience extraction</h2>
<p>script named “static_salience_in_video.py”</p>
<pre class="python"><code>
import cv2
import sys
import os

stimulus_name = sys.argv[1]
input_folder = &quot;stimuli_pics&quot;
output_folder = &quot;stimuli_salience&quot;

#create stimulus-specific output folder if it does not exist
if not os.path.exists(os.path.join(output_folder,stimulus_name)):
    os.mkdir(os.path.join(output_folder,stimulus_name))

#get and sort input image data - see also VidToImg.py
name_images = os.listdir(os.path.join(input_folder,stimulus_name)) #get individuals images of video file
name_images.sort(key=lambda f: int(&#39;&#39;.join(filter(str.isdigit, f)))) #sort alphanumerically
n_images = len(name_images)

# initialize OpenCV&#39;s static saliency spectral residual detector and
saliency = cv2.saliency.StaticSaliencySpectralResidual_create()

#### saliency model after
# Hou, X., &amp; Zhang, L. (2007, June). Saliency detection: A spectral residual approach. In 2007 IEEE Conference on computer vision and pattern recognition (pp. 1-8). Ieee.

#loop over images
i=0
while(i&lt;n_images):
    image = cv2.imread(os.path.join(input_folder,stimulus_name,name_images[i])) #read image
    (success, saliencyMap) = saliency.computeSaliency(image) # compute the saliency map
    saliencyMap = (saliencyMap * 255).astype(&quot;uint8&quot;) #changes 0-1 values to 255 grayscale
    cv2.imwrite(os.path.join(output_folder,stimulus_name,stimulus_name+&quot;_salience&quot;+str(i)+&quot;.jpg&quot;), saliencyMap) #write salience map
    print(os.path.join(output_folder,stimulus_name,stimulus_name+&quot;_salience&quot;+str(i)+&quot;.jpg&quot;)) #print processed salience map

    #show image
    #cv2.imshow(&quot;Image&quot;, image)
    #cv2.imshow(&quot;Salience&quot;, saliencyMap)
    #cv2.waitKey(20)

    i+=1
</code></pre>
</div>
</div>
<div id="motion-salience---opencv" class="section level1">
<h1>motion salience - OpenCV</h1>
<p>execute as BAT file</p>
<pre class="r"><code>&quot;C:\Users\Nico\AppData\Local\Programs\Python\Python37\python.exe&quot;@echo off

ECHO Identify MOTION SALIENCE of SCENES:
ECHO INFO: scenes are previously split by split_images_to_scenes.py...
ECHO -----------------------------------------------------

REM independent of environment variables (full path files)
REM path_to_python = where py

ECHO IDENTIFY MOTION SALIENCE...
&quot;C:\Users\Nico\AppData\Local\Programs\Python\Python37\python.exe&quot; &quot;C:\Users\Nico\PowerFolders\project_video_salience\motion_salience_in_video_MOG2.py&quot; 50faces
ECHO 50faces DONE
&quot;C:\Users\Nico\AppData\Local\Programs\Python\Python37\python.exe&quot; &quot;C:\Users\Nico\PowerFolders\project_video_salience\motion_salience_in_video_MOG2.py&quot; artist
ECHO artist DONE
&quot;C:\Users\Nico\AppData\Local\Programs\Python\Python37\python.exe&quot; &quot;C:\Users\Nico\PowerFolders\project_video_salience\motion_salience_in_video_MOG2.py&quot; birds
ECHO birds DONE
&quot;C:\Users\Nico\AppData\Local\Programs\Python\Python37\python.exe&quot; &quot;C:\Users\Nico\PowerFolders\project_video_salience\motion_salience_in_video_MOG2.py&quot; coralreef
ECHO coralreef DONE
&quot;C:\Users\Nico\AppData\Local\Programs\Python\Python37\python.exe&quot; &quot;C:\Users\Nico\PowerFolders\project_video_salience\motion_salience_in_video_MOG2.py&quot; dollhouse
ECHO dollhouse DONE
&quot;C:\Users\Nico\AppData\Local\Programs\Python\Python37\python.exe&quot; &quot;C:\Users\Nico\PowerFolders\project_video_salience\motion_salience_in_video_MOG2.py&quot; flowersstars
ECHO flowersstars DONE
&quot;C:\Users\Nico\AppData\Local\Programs\Python\Python37\python.exe&quot; &quot;C:\Users\Nico\PowerFolders\project_video_salience\motion_salience_in_video_MOG2.py&quot; musicbooth
ECHO musicbooth DONE
&quot;C:\Users\Nico\AppData\Local\Programs\Python\Python37\python.exe&quot; &quot;C:\Users\Nico\PowerFolders\project_video_salience\motion_salience_in_video_MOG2.py&quot; Pingu_doctors
ECHO Pingu_doctors DONE
&quot;C:\Users\Nico\AppData\Local\Programs\Python\Python37\python.exe&quot; &quot;C:\Users\Nico\PowerFolders\project_video_salience\motion_salience_in_video_MOG2.py&quot; Pingu1
ECHO Pingu1 DONE

PAUSE</code></pre>
<div id="motion-salience-extraction" class="section level2">
<h2>motion salience extraction</h2>
<p>script names “motion_salience_in_video_MOG2.py”</p>
<pre class="python"><code>
import cv2
import sys
import os

###NOTE: takes videos split to scenes as input - as videos with different scenes will cause the motion alorithm to provide false positives

video_folder = &quot;stimuli_scene&quot;

input_folder = sys.argv[1]
output_folder = &quot;motion_salience&quot;

scenes = os.listdir(os.path.join(video_folder,input_folder))
scenes.sort(key=lambda f: int(&#39;&#39;.join(filter(str.isdigit, f)))) #sort alphanumerically

for scene in scenes:

    #input_folder = sys.argv[1]
    # for loop stimulus name
    stimulus_file = scene
    stimulus_name = os.path.splitext(scene)[0]

    #create stimulus-specific output folder if it does not exist
    output_path = os.path.join(output_folder,input_folder,stimulus_name)
    if not os.path.exists(output_path):
       os.makedirs(output_path)

    #open video of the scene (ceated by split_images_to_scenes)
    video_path = os.path.join(video_folder,input_folder,stimulus_file)
    cap = cv2.VideoCapture(video_path)

    # amount_of_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)
    # print(amount_of_frames)

    #---&gt; identify MOTION SALIENCE
    # loop over frames from the video file stream
    i=1
    while (cap.isOpened()):

        # grab the frame from the video
        # cap.set(1,i) #set frame of the video stream
        boolr, frame = cap.read() #read the frame of the stream
        if boolr == False: #break if cannot be read
            break
        print(i)

        #if saliency does not exist create it
        try:
            saliency
        except:
            #saliency = cv2.createBackgroundSubtractorMOG2(history = 25, detectShadows = False)
            saliency = cv2.createBackgroundSubtractorMOG2(history = 500, varThreshold = 30, detectShadows = False)

            #default varThresholdGen = 9
            #default varThreshold = 16
            #default history = 500 &lt;- shorter adaption

        ## convert the input frame to grayscale and compute the saliency
        ## map based on the motion model
        #gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        #(success, saliencyMap) = saliency.computeSaliency(gray)
        #saliencyMap = (saliencyMap * 255).astype(&quot;uint8&quot;)
        #print(success)

        #apply foreground segmentation
        fgMask = saliency.apply(frame, learningRate = 1/i)

        #add frame counter to original image
        cv2.rectangle(frame, (10, 2), (100,20), (255,255,255), -1)
        cv2.putText(frame, str(cap.get(cv2.CAP_PROP_POS_FRAMES)), (15, 15),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5 , (0,0,0))

        #print to screen
        cv2.imshow(&quot;Image&quot;, frame)
        cv2.imshow(&quot;Salience&quot;, fgMask)

        # #save to file
        #cv2.imwrite(os.path.join(output_path,stimulus_name+&quot;_motion_salience_frame&quot;+str(i)+&quot;.jpg&quot;), fgMask) #write salience map
        #print(os.path.join(output_path,stimulus_name+&quot;_motion_salience&quot;+str(i)+&quot;.jpg&quot;)) #print processed salience map

        i=i+1 #increase count

        keyboard = cv2.waitKey(30)
        if keyboard == &#39;q&#39; or keyboard == 27:
            break

    cap.release()
    cv2.destroyAllWindows()
</code></pre>
<br>
<p>
<button type="button" class="btn btn-default btn-workflowr btn-workflowr-sessioninfo" data-toggle="collapse" data-target="#workflowr-sessioninfo" style="display: block;">
<span class="glyphicon glyphicon-wrench" aria-hidden="true"></span> Session information
</button>
</p>
<div id="workflowr-sessioninfo" class="collapse">
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>R version 3.6.1 (2019-07-05)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 19043)

Matrix products: default

locale:
[1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252   
[3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C                   
[5] LC_TIME=German_Germany.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] workflowr_1.6.2

loaded via a namespace (and not attached):
 [1] Rcpp_1.0.3      rprojroot_1.3-2 digest_0.6.23   later_1.0.0    
 [5] R6_2.4.1        backports_1.1.5 git2r_0.26.1    magrittr_1.5   
 [9] evaluate_0.14   highr_0.8       stringi_1.4.5   rlang_0.4.8    
[13] fs_1.3.1        promises_1.1.0  whisker_0.4     rmarkdown_2.0  
[17] tools_3.6.1     stringr_1.4.0   glue_1.4.2      httpuv_1.5.2   
[21] xfun_0.11       yaml_2.2.0      compiler_3.6.1  htmltools_0.4.0
[25] knitr_1.26     </code></pre>
</div>
</div>
</div>


<!-- Adjust MathJax settings so that all math formulae are shown using
TeX fonts only; see
http://docs.mathjax.org/en/latest/configuration.html.  This will make
the presentation more consistent at the cost of the webpage sometimes
taking slightly longer to load. Note that this only works because the
footer is added to webpages before the MathJax javascript. -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
